{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48eb704-0f28-497c-99ed-31f5ce5ce921",
   "metadata": {},
   "source": [
    "### TRUST_MCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ca086d-200e-4c5f-ab55-fffdc8248e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_rounds': 5, 'batch_size': 64, 'learning_rate': 0.001, 'num_clients': 3}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFIG CELL\n",
    "from omegaconf import OmegaConf\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class TrainingConfig(BaseModel):\n",
    "    num_rounds: int = 5\n",
    "    batch_size: int = 64\n",
    "    learning_rate: float = 0.001\n",
    "    num_clients: int = 3\n",
    "\n",
    "config = TrainingConfig()\n",
    "OmegaConf.create(config.dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb9fa9b-713e-43a6-93c9-176c6f8cd3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET CELL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "class ToNIoTDataset:\n",
    "    def __init__(self, partition_id, total_partitions, config):\n",
    "        np.random.seed(42 + partition_id)\n",
    "\n",
    "        n_samples = 6000\n",
    "        n_features = 42\n",
    "\n",
    "        # Generate normal (label 0) and anomaly (label 1)\n",
    "        normal = np.random.normal(0, 1, (int(0.8*n_samples), n_features))\n",
    "        anomaly = np.random.normal(2, 1.5, (int(0.2*n_samples), n_features))\n",
    "        X = np.vstack((normal, anomaly))\n",
    "        y = np.hstack((np.zeros(normal.shape[0]), np.ones(anomaly.shape[0])))\n",
    "\n",
    "        X, y = X[partition_id::total_partitions], y[partition_id::total_partitions]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        self.train_loader = DataLoader(TensorDataset(torch.tensor(X_train).float(), torch.tensor(y_train).long()), batch_size=config.batch_size)\n",
    "        self.test_loader = DataLoader(TensorDataset(torch.tensor(X_test).float(), torch.tensor(y_test).long()), batch_size=config.batch_size)\n",
    "\n",
    "        self.input_dim = X.shape[1]\n",
    "        self.num_classes = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a5ab0cb-e965-464c-8fa8-7dd5366a4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CELL\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.out = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61327d79-634b-4e82-bd23-de147b8ef5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIENT CELL\n",
    "from flwr.client import NumPyClient\n",
    "\n",
    "def get_weights(model):\n",
    "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "def set_weights(model, weights):\n",
    "    params_dict = zip(model.state_dict().keys(), weights)\n",
    "    state_dict = {k: torch.tensor(v) for k, v in params_dict}\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "class TrustMCClient(NumPyClient):\n",
    "    def __init__(self, model, train_loader, test_loader):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_weights(self.model)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_weights(self.model, parameters)\n",
    "        self.model.train()\n",
    "        for X, y in self.train_loader:\n",
    "            self.optim.zero_grad()\n",
    "            loss = self.loss_fn(self.model(X), y)\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "        return get_weights(self.model), len(self.train_loader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_weights(self.model, parameters)\n",
    "        self.model.eval()\n",
    "        correct, total = 0, 0\n",
    "        loss_total = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.test_loader:\n",
    "                preds = self.model(X)\n",
    "                loss = self.loss_fn(preds, y)\n",
    "                loss_total += loss.item()\n",
    "                correct += (preds.argmax(1) == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        return loss_total / total, total, {\"accuracy\": correct / total}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90b90c4a-da3e-4810-a010-96a5f4bd4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATEGY CELL\n",
    "import warnings\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from scipy.stats import spearmanr\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.common import parameters_to_ndarrays, ndarrays_to_parameters\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class TrustMCStrategy(FedAvg):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        percentile: float = 40,\n",
    "        eta0: float = 0.10,\n",
    "        lam: float = 0.2,\n",
    "        kappa: float = 5.0,\n",
    "        temp0: float = 1.0,\n",
    "        temp_min: float = 0.3,\n",
    "        temp_decay: float = 0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        # --- Bayesian-mirror state ---\n",
    "        self.theta = np.array([1/3, 1/3, 1/3])  # α,β,γ on the 2-simplex\n",
    "        self.t = 0                              # round counter\n",
    "        self.lam = lam\n",
    "        self.kappa = kappa\n",
    "        self.eta0 = eta0\n",
    "        # --- softmax params & thresholding ---\n",
    "        self.percentile = percentile\n",
    "        self.temp0 = temp0\n",
    "        self.temp_min = temp_min\n",
    "        self.temp_decay = temp_decay\n",
    "        # track previous global accuracy for ΔAcc\n",
    "        self.prev_global_accuracy = 0.0\n",
    "\n",
    "    def aggregate_fit(self, server_round, results, failures):\n",
    "        \"\"\"Per-round:\n",
    "           1) Compute Spearman ρ for each metric\n",
    "           2) Bayesian-mirror update of θ\n",
    "           3) Compute per-client trust scores T\n",
    "           4) Dynamic percentile threshold → trusted set\n",
    "           5) Softmax weighting → w_i\n",
    "           6) Weighted avg of client params → new global params\n",
    "        \"\"\"\n",
    "        if not results:\n",
    "            return super().aggregate_fit(server_round, results, failures)\n",
    "\n",
    "        # 1) Extract per-client metrics and ΔAcc\n",
    "        metric_names = [\"cos\", \"ent\", \"rep\"]\n",
    "        # build (n_clients, 3) array M and (n,) ΔAcc\n",
    "        Ms = []\n",
    "        ΔAcc = []\n",
    "        for cid, fit_res in results:\n",
    "            m = [fit_res.metrics.get(name, 0.0) for name in metric_names]\n",
    "            Ms.append(m)\n",
    "            acc = fit_res.metrics.get(\"accuracy\", 0.0)\n",
    "            ΔAcc.append(acc - self.prev_global_accuracy)\n",
    "        M = np.array(Ms)           # shape (n,3)\n",
    "        ΔAcc = np.array(ΔAcc)      # shape (n,)\n",
    "\n",
    "        # 2) Spearman ρ_j for each metric j\n",
    "        rhos = []\n",
    "        for j in range(M.shape[1]):\n",
    "            ρ, _ = spearmanr(M[:, j], ΔAcc)\n",
    "            # handle constant or nan cases\n",
    "            rhos.append(0.0 if np.isnan(ρ) else float(ρ))\n",
    "        ρ = np.array(rhos)         # shape (3,)\n",
    "\n",
    "        # 3) Bayesian-mirror θ update\n",
    "        self.t += 1\n",
    "        s = (ρ + 1.0) / 2.0                               # evidence\n",
    "        θ_bar = (1 - self.lam) * self.theta + self.lam * s\n",
    "        η_t = self.eta0 / sqrt(self.t)\n",
    "        g = np.exp(η_t * ρ)                              # mirror tilt\n",
    "        θ_new = θ_bar * g\n",
    "        θ_new /= θ_new.sum()                             # re-normalise\n",
    "        self.theta = θ_new\n",
    "\n",
    "        # 4) Trust scores T_i = θ·metrics_i\n",
    "        T = M.dot(self.theta)                            # shape (n,)\n",
    "\n",
    "        # 5) Dynamic threshold τ(t)\n",
    "        τ = np.percentile(T, self.percentile)\n",
    "        trusted = T >= τ\n",
    "\n",
    "        # 6) Soft-max weights\n",
    "        temp_t = max(self.temp0 - self.temp_decay * (server_round - 1), self.temp_min)\n",
    "        w = np.zeros_like(T)\n",
    "        if trusted.any():\n",
    "            z = np.exp(T[trusted] / temp_t)\n",
    "            w[trusted] = z / z.sum()\n",
    "\n",
    "        # 7) Weighted average of client models\n",
    "        #    Build list of (weights_i, client_params_i)\n",
    "        client_arrays = [parameters_to_ndarrays(fit_res.parameters) \n",
    "                         for _, fit_res in results]\n",
    "        # weighted sum over clients\n",
    "        new_weights = []\n",
    "        for layer_idx in range(len(client_arrays[0])):\n",
    "            # sum_i (w_i * layer_i)\n",
    "            layer_sum = sum(w_i * arr[layer_idx]\n",
    "                            for w_i, arr in zip(w, client_arrays))\n",
    "            new_weights.append(layer_sum)\n",
    "\n",
    "        # 8) Update prev_global_accuracy for next round\n",
    "        #    Approximate new global accuracy by weighted client accuracies\n",
    "        self.prev_global_accuracy = float((np.array([fit_res.metrics.get(\"accuracy\", 0.0)\n",
    "                                                    for _, fit_res in results]) * w).sum())\n",
    "\n",
    "        # 9) Return new aggregated parameters and empty metrics dict\n",
    "        return ndarrays_to_parameters(new_weights), {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da5bda41-30b5-4f63-9b88-586de345e904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: Passing either `server`, `config`, `strategy` or `client_manager` directly to the ServerApp constructor is deprecated.\n",
      "\n",
      "            Check the following `FEATURE UPDATE` warning message for the preferred\n",
      "            new mechanism to use this feature in Flower.\n",
      "        \n",
      "\u001b[93mWARNING \u001b[0m:   FEATURE UPDATE: Pass `ServerApp` arguments wrapped in a `flwr.server.ServerAppComponents` object that gets returned by a function passed as the `server_fn` argument to the `ServerApp` constructor. For example: \n",
      "            ------------------------------------------------------------\n",
      "        \n",
      "\n",
      "        def server_fn(context: Context):\n",
      "            server_config = ServerConfig(num_rounds=3)\n",
      "            strategy = FedAvg()\n",
      "            return ServerAppComponents(\n",
      "                strategy=strategy,\n",
      "                server_config=server_config,\n",
      "        )\n",
      "\n",
      "        app = ServerApp(server_fn=server_fn)\n",
      "\n",
      "            ------------------------------------------------------------\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=1, no round_timeout\n",
      "\u001b[91mERROR \u001b[0m:     Backend `ray`, is not supported. Use any of [] or add support for a new backend.\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[91mERROR \u001b[0m:     Unable to import module `ray`.\n",
      "\n",
      "    To install the necessary dependencies, install `flwr` with the `simulation` extra:\n",
      "\n",
      "        pip install -U \"flwr[simulation]\"\n",
      "    \n",
      "\u001b[91mERROR \u001b[0m:     ServerApp thread raised an exception: 'function' object has no attribute 'client_manager'\n",
      "\u001b[91mERROR \u001b[0m:     An exception occurred !! 'ray'\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/flwr/simulation/run_simulation.py\", line 387, in _main_loop\n",
      "    vce.start_vce(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 334, in start_vce\n",
      "    raise ex\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 322, in start_vce\n",
      "    backend_type = supported_backends[backend_name]\n",
      "                   ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
      "KeyError: 'ray'\n",
      "\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/flwr/simulation/run_simulation.py\", line 285, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "                      ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/flwr/server/run_serverapp.py\", line 62, in run\n",
      "    server_app(grid=grid, context=context)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/flwr/server/server_app.py\", line 166, in __call__\n",
      "    start_grid(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/flwr/server/compat/app.py\", line 83, in start_grid\n",
      "    grid, initialized_server.client_manager()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'function' object has no attribute 'client_manager'\n",
      "\n",
      "Exception in thread Thread-6 (server_th_with_start_checks):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/siddhantgond/.local/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/anaconda3/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/flwr/simulation/run_simulation.py\", line 285, in server_th_with_start_checks\n",
      "    updated_context = _run(\n",
      "                      ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/flwr/server/run_serverapp.py\", line 62, in run\n",
      "    server_app(grid=grid, context=context)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/flwr/server/server_app.py\", line 166, in __call__\n",
      "    start_grid(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/flwr/server/compat/app.py\", line 83, in start_grid\n",
      "    grid, initialized_server.client_manager()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'function' object has no attribute 'client_manager'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception in ServerApp thread",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/flwr/simulation/run_simulation.py:387\u001b[39m, in \u001b[36m_main_loop\u001b[39m\u001b[34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, exit_event, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;66;03m# Start Simulation Engine\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m \u001b[43mvce\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_vce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_app_attr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_app_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_config_json_stream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend_config_stream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapp_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstate_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf_stop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf_stop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflwr_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflwr_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m updated_context = output_context_queue.get(timeout=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/vce_api.py:334\u001b[39m, in \u001b[36mstart_vce\u001b[39m\u001b[34m(backend_name, backend_config_json_stream, app_dir, is_app, f_stop, run, flwr_dir, client_app, client_app_attr, num_supernodes, state_factory, existing_nodes_mapping)\u001b[39m\n\u001b[32m    332\u001b[39m         log(ERROR, error_messages_backends[backend_name])\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackend_fn\u001b[39m() -> Backend:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/vce_api.py:322\u001b[39m, in \u001b[36mstart_vce\u001b[39m\u001b[34m(backend_name, backend_config_json_stream, app_dir, is_app, f_stop, run, flwr_dir, client_app, client_app_attr, num_supernodes, state_factory, existing_nodes_mapping)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     backend_type = \u001b[43msupported_backends\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[31mKeyError\u001b[39m: 'ray'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/flwr/simulation/run_simulation.py:410\u001b[39m, in \u001b[36m_main_loop\u001b[39m\u001b[34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, exit_event, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001b[39m\n\u001b[32m    409\u001b[39m     success = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAn error was encountered. Ending simulation.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    413\u001b[39m     \u001b[38;5;66;03m# Trigger stop event\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: An error was encountered. Ending simulation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ServerAppComponents(strategy=strategy, config=ServerConfig(num_rounds=config.num_rounds))\n\u001b[32m     19\u001b[39m server_app = ServerApp(server_fn)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_cpus\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/flwr/simulation/run_simulation.py:228\u001b[39m, in \u001b[36mrun_simulation\u001b[39m\u001b[34m(server_app, client_app, num_supernodes, backend_name, backend_config, enable_tf_gpu_growth, verbose_logging)\u001b[39m\n\u001b[32m    218\u001b[39m     warn_deprecated_feature_with_example(\n\u001b[32m    219\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing `enable_tf_gpu_growth=True` is deprecated.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    220\u001b[39m         example_message=\u001b[33m\"\u001b[39m\u001b[33mInstead, set the `TF_FORCE_GPU_ALLOW_GROWTH` environment \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    223\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mflwr.simulation.run_simulationt(...)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m     )\n\u001b[32m    226\u001b[39m _check_ray_support(backend_name)\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m _ = \u001b[43m_run_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_logging\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexit_event\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEventType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPYTHON_API_RUN_SIMULATION_LEAVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/flwr/simulation/run_simulation.py:527\u001b[39m, in \u001b[36m_run_simulation\u001b[39m\u001b[34m(num_supernodes, exit_event, client_app, server_app, backend_name, backend_config, client_app_attr, server_app_attr, server_app_run_config, app_dir, flwr_dir, run, enable_tf_gpu_growth, verbose_logging, is_app)\u001b[39m\n\u001b[32m    523\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m asyncio_loop_running:\n\u001b[32m    524\u001b[39m         \u001b[38;5;66;03m# Set logger propagation to False to prevent duplicated log output in Colab.\u001b[39;00m\n\u001b[32m    525\u001b[39m         logger = set_logger_propagation(logger, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m     updated_context = \u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m updated_context\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/site-packages/flwr/simulation/run_simulation.py:425\u001b[39m, in \u001b[36m_main_loop\u001b[39m\u001b[34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, exit_event, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001b[39m\n\u001b[32m    423\u001b[39m         serverapp_th.join()\n\u001b[32m    424\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m server_app_thread_has_exception.is_set():\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mException in ServerApp thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    427\u001b[39m log(DEBUG, \u001b[33m\"\u001b[39m\u001b[33mStopping Simulation Engine now.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m updated_context\n",
      "\u001b[31mRuntimeError\u001b[39m: Exception in ServerApp thread"
     ]
    }
   ],
   "source": [
    "# SIMULATION CELL\n",
    "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr.client import ClientApp\n",
    "from flwr.common import Context\n",
    "\n",
    "def client_fn(context: Context):\n",
    "    partition_id = int(context.node_config[\"partition-id\"])\n",
    "    dataset = ToNIoTDataset(partition_id, config.num_clients, config)\n",
    "    model = SimpleModel(dataset.input_dim, dataset.num_classes)\n",
    "    return TrustMCClient(model, dataset.train_loader, dataset.test_loader).to_client()\n",
    "\n",
    "client_app = ClientApp(client_fn)\n",
    "\n",
    "def server_fn(context):\n",
    "    strategy = TrustMCStrategy()\n",
    "    return ServerAppComponents(strategy=strategy, config=ServerConfig(num_rounds=config.num_rounds))\n",
    "\n",
    "server_app = ServerApp(server_fn)\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server_app,\n",
    "    client_app=client_app,\n",
    "    num_supernodes=config.num_clients,\n",
    "    backend_config={\"num_cpus\": 4}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15bc3d-058a-403b-8e73-b6a4f1af28e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2c2f4-ea9b-456f-9b3b-29d2556e23c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7097ab-c125-4f8c-a4c3-4e2e43be26dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227f41b-1fd4-4b99-b0c6-b36f89454f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb36d50-a792-4ac1-93b8-3b367ba00d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef8690-83ae-4552-95b9-503cb782fcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803ce0ac-5ab7-4693-a0d6-406e42225deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27670907-e0af-4c87-80c2-ab68712efe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
